# -*- coding: utf-8 -*-
"""week_5_lesson_2c.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q270u1jyZaa72dgcHt2aKZMb3HvBcKbh

## A JOKE-GENERATING BOT USING A WRITER-CRITIC MODEL SETUP
"""

!pip install -q langgraph
!pip install -q pyjokes
print("LangGraph Installed!")

import os
from typing import Literal
from langgraph.graph import StateGraph, END
from pathlib import Path

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files

!cp /content/drive/MyDrive/utility/week_5_lesson_2a.py /content

!cp /content/drive/MyDrive/utility/prompt_builder.py /content
!cp /content/drive/MyDrive/utility/llm.py /content
!cp /content/drive/MyDrive/utility/utils.py /content
!cp /content/drive/MyDrive/utility/paths.py /content

!pip install -q -U langchain-openai
!pip install -q -U langchain-groq
!pip install -q -U python-dotenv

#import week_5_lesson_2a

from week_5_lesson_2a import (
    Joke, JokeState, show_menu, reset_joke,
    fetch_joke, exit_bot, route_choice, print_joke
)
from prompt_builder import build_prompt_from_config
from utils import load_config
from llm import get_llm
from paths import PROMPT_CONFIG_FILE_PATH

"""## Extended State"""

class AgenticJokeState(JokeState):
  latest_joke: str = ""
  approved: bool = False
  retry_count: int = 0

"""## Prompt Config"""

prompt_config = load_config(PROMPT_CONFIG_FILE_PATH)

"""## Writer Critic Node Factories"""

def make_writer_node(writer_llm):
  def writer_node(state: AgenticJokeState) -> dict:
    config = prompt_config["joke_writer_config"]
    prompt = build_prompt_from_config(config, input_data="", app_config=None)
    prompt += f"\\n\\nThe category is: {state.category}"
    response = writer_llm.invoke(prompt)
    return {"latest_joke": response.content}

  return writer_node


def make_critic_node(critic_llm):
  def critic_node(state: AgenticJokeState) -> dict:
    config = prompt_config["joke_critic_config"]
    prompt = build_prompt_from_config(config, input_data=state.latest_joke, app_config=None)
    decision = critic_llm.invoke(prompt).content.strip().lower()
    approved = "yes" in decision
    return {"approved": approved, "retry_count": state.retry_count + 1}

  return critic_node


def show_final_joke(state: AgenticJokeState) -> dict:
  joke = Joke(text=state.latest_joke, category=state.category)
  print_joke(joke)
  return {"jokes": [joke], "retry_count": 0, "approved": False, "latest_joke": ""}


def writer_critic_router(state: AgenticJokeState) -> str:
  if state.approved or state.retry >= 5:
    return "show_final_joke"
  return "writer"  # **************************************************** ?


def update_category(state: AgenticJokeState) -> dict:
  categories = ["dad developer", "chuck norris developer", "general"]
  emoji_map = {
      "knock-knock": "K-K",
      "dad developer": "D-D",
      "chuck norris developer": "C-N-D",
      "general": "G"
  }

  print("==HELLO++" * 55)
  print("  #CATEGORY SELECTION")
  print("=" * 60)

  print("=" * 60)

  try:
    selection = int(input("  Enter category number: ").strip())
    if 0 <= selection < len(categories):
      selected_category = categories[selection]
      print(f" Category changed to: {selected_category.upper()}")
      return {"category": selected_category}
    else:
      print("  XXX  Invalid choice. Keep current category.")
      return {}
  except ValueError:
    print("  XXX  Please enter a valid number. Keep current category.")
    return {}

"""## Graph Assembly"""

def build_joke_graph(
    writer_model: str = 'gpt-4o-mini',
    critic_model: str = 'gpt-4o-mini',
    writer_temp: float = 0.95,
    critic_temp: float = 0.1
):

  writer_llm = get_llm(writer_model, writer_temp)
  critic_llm = get_llm(critic_model, critic_temp)

  builder = StateGraph(AgenticJokeState)

  builder.add_node("show_menu", show_menu)
  builder.add_node("update_category", update_category)
  builder.add_node("exit_bot", exit_bot)
  builder.add_node("writer", make_writer_node(writer_llm))
  builder.add_node("critic", make_critic_node(critic_llm))
  builder.add_node("show_final_joke", show_final_joke)

  builder.set_entry_point("show_menu")

  builder.add_conditional_edges(
      "show_menu",
      route_choice,
      {
          "fetch_joke": "writer",
          "update_category": "update_category",
          "exit_bot": "exit_bot",
      },
  )

  # 'builder.add_edge()" is used to connect two nodes (states) in your workflow.
  # It defines the transition from one step to the next.
  builder.add_edge("update_category", "show_menu")
  builder.add_edge("writer", "critic")
  builder.add_conditional_edges(
      "critic",
      writer_critic_router,
      {"writer": "writer", "show_final_joke": "show_final_joke"}
  )
  builder.add_edge("show_final_joke", "show_menu")
  builder.add_edge("exit_bot", END)

  return builder.compile()

## Set OPENAI_API_KEY
## Hide key

import getpass
os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key")

"""## Entry Point"""

def main():
  print("\n Starting joke bot with writer-critic-LLM loop...")
  graph = build_joke_graph(writer_temp=0.8, critic_temp=0.1)
  final_state = graph.invoke(
      AgenticJokeState(category="dad developer"), config={"recursion_limit": 200}
  )
  print("\n Done: Final Joke Count:", len(final_state["jokes"]))


if __name__== "__main__":
  main()

