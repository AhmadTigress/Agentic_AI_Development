# -*- coding: utf-8 -*-
"""Agentic_Tools.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KblfCWzn6XQmezRKV26TsqMxmbM2f89G
"""

# Installation

#!pip -q install langgraph
#!pip -q install langchain-community langchain_openai
#!pip install -q -U langchain_tavily

"""## Essential Imports and Set-Up"""

# Openai api key set-up

import os

os.environ["OPENAI_API_KEY"] = input("Enter your OpenAI API key: ")

from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
#from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_tavily import TavilySearch
from langchain_openai import ChatOpenAI


from dotenv import load_dotenv
load_dotenv()

# Set-up LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

"""## Define the Agent's Memory and Tool"""

# Define your Agent State(your agent's memory)
class State(TypedDict):
  messages: Annotated[list, add_messages]

# Create your tools - your agent's capabilities
def get_tools():
  return [
      TavilySearchResults(max_results=3, search_depth="advanced")
  ]

"""## The Thinking Node"""

def llm_node(state: State):
  """Your agent's brain - decides whether to use tools or respond"""
  tools = get_tools()
  llm_with_tools = llm.bind_tools(tools)

  response = llm_with_tools.invoke(state["messages"])
  return {"messages": [response]}

"""## The Action Node"""

# The tools node

def tools_node(state: State):
  """The Agent's hand - executes the choosen tools"""
  tools = get_tools()
  tool_registry = {tool.name: tool for tool in tools}

  last_message = state["messages"][-1]
  tool_messages = []

  # Execute each tool the agent requested
  for tool_call in last_message.tool_calls:
    tool = tool_registry[tool_call["name"]]
    result = tool.invoke(tool_call["args"])

    # Send the result to the agent
    tool_messages.append(ToolMessage(
        content=str(result),
        tool_call_id=tool_call["id"]
    ))

  return {"messages": tool_messages}

"""## The Decision Logic"""

def should_continue(state: State):
  """Decide whether to continue or use fina answer"""
  last_message = state["messages"][-1]

  if hasattr(last_message, "tool_call") and last_message.tool_calls:
    return "tools"
  return END

"""## Building the Complete Workflow"""

def create_agent():
  graph = StateGraph(State)

  # Add the nodes
  graph.add_node("llm", llm_node)
  graph.add_node("tools", tools_node)

  # Set the starting point
  graph.set_entry_point("llm")

  # Add the flow logic
  graph.add_conditional_edges("llm", should_continue, {"tools": "tools", END: END})
  graph.add_edge("tools", "llm")

  return graph.compile()

"""## Testing your enhanced-agent"""

import os

os.environ["TAVILY_API_KEY"] = input("Enter your Tavily API key: ")

agent = create_agent()

# Test it
initial_state ={
    "messages": [
        SystemMessage(content="You are a helpful assistant with access to web search. Use the search tool when you need current information."),
        HumanMessage(content="What is the latest news about AI developments in 2025?")
    ]
}

result = agent.invoke(initial_state)
print(result["messages"][-1].content)

